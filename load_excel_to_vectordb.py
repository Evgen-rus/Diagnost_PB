#!/usr/bin/env python3
# -*- coding: utf-8 -*-
"""
–°–∫—Ä–∏–ø—Ç –¥–ª—è –∑–∞–≥—Ä—É–∑–∫–∏ –¥–∞–Ω–Ω—ã—Ö –∏–∑ database_v1.xlsx –≤ –≤–µ–∫—Ç–æ—Ä–Ω—É—é –±–∞–∑—É –¥–∞–Ω–Ω—ã—Ö

–û–ø–∏—Å–∞–Ω–∏–µ: –ß–∏—Ç–∞–µ—Ç Excel —Ñ–∞–π–ª —Å —á–∞–Ω–∫–∞–º–∏ –¥–æ–∫—É–º–µ–Ω—Ç–æ–≤ –∏ –∑–∞–≥—Ä—É–∂–∞–µ—Ç –∏—Ö –≤ SQLite –±–∞–∑—É
–¥–ª—è –ø–æ—Å–ª–µ–¥—É—é—â–µ–≥–æ —Å–æ–∑–¥–∞–Ω–∏—è FAISS –∏–Ω–¥–µ–∫—Å–∞
"""

import pandas as pd
import sqlite3
import os
import logging
from pathlib import Path
from datetime import datetime

# –ù–∞—Å—Ç—Ä–æ–π–∫–∞ –ª–æ–≥–∏—Ä–æ–≤–∞–Ω–∏—è
logging.basicConfig(
    level=logging.INFO,
    format='%(asctime)s - %(levelname)s - %(message)s'
)
logger = logging.getLogger(__name__)

# –ü—É—Ç—å –∫ –±–∞–∑–µ –¥–∞–Ω–Ω—ã—Ö
DB_PATH = os.path.join(os.getcwd(), 'knowledge_base_v2.db')

def create_chunks_table(conn):
    """
    –°–æ–∑–¥–∞–µ—Ç —Ç–∞–±–ª–∏—Ü—É chunks –≤ –±–∞–∑–µ –¥–∞–Ω–Ω—ã—Ö –µ—Å–ª–∏ –æ–Ω–∞ –Ω–µ —Å—É—â–µ—Å—Ç–≤—É–µ—Ç
    
    –ü–∞—Ä–∞–º–µ—Ç—Ä—ã:
    conn: —Å–æ–µ–¥–∏–Ω–µ–Ω–∏–µ —Å –±–∞–∑–æ–π –¥–∞–Ω–Ω—ã—Ö SQLite
    """
    cursor = conn.cursor()
    
    # –°–æ–∑–¥–∞–µ–º —Ç–∞–±–ª–∏—Ü—É chunks
    cursor.execute('''
        CREATE TABLE IF NOT EXISTS chunks (
            id INTEGER PRIMARY KEY AUTOINCREMENT,
            chunk_id TEXT UNIQUE NOT NULL,
            document_id INTEGER,
            doc_type_short TEXT,
            doc_type_full TEXT,
            doc_number TEXT,
            file_name TEXT,
            chunk_index INTEGER,
            chunk_text TEXT NOT NULL,
            created_at TIMESTAMP DEFAULT CURRENT_TIMESTAMP
        )
    ''')
    
    # –°–æ–∑–¥–∞–µ–º –∏–Ω–¥–µ–∫—Å—ã –¥–ª—è –±—ã—Å—Ç—Ä–æ–≥–æ –ø–æ–∏—Å–∫–∞
    cursor.execute('CREATE INDEX IF NOT EXISTS idx_chunks_document_id ON chunks(document_id)')
    cursor.execute('CREATE INDEX IF NOT EXISTS idx_chunks_chunk_index ON chunks(chunk_index)')
    cursor.execute('CREATE INDEX IF NOT EXISTS idx_chunks_doc_type ON chunks(doc_type_short)')
    cursor.execute('CREATE INDEX IF NOT EXISTS idx_chunks_file_name ON chunks(file_name)')
    
    conn.commit()
    logger.info("–¢–∞–±–ª–∏—Ü–∞ chunks —Å–æ–∑–¥–∞–Ω–∞ –∏–ª–∏ —É–∂–µ —Å—É—â–µ—Å—Ç–≤—É–µ—Ç")

def load_excel_to_database(excel_file: str, db_path: str):
    """
    –ó–∞–≥—Ä—É–∂–∞–µ—Ç –¥–∞–Ω–Ω—ã–µ –∏–∑ Excel —Ñ–∞–π–ª–∞ –≤ –±–∞–∑—É –¥–∞–Ω–Ω—ã—Ö SQLite
    
    –ü–∞—Ä–∞–º–µ—Ç—Ä—ã:
    excel_file (str): –ü—É—Ç—å –∫ Excel —Ñ–∞–π–ª—É
    db_path (str): –ü—É—Ç—å –∫ –±–∞–∑–µ –¥–∞–Ω–Ω—ã—Ö SQLite
    """
    logger.info(f"–ù–∞—á–∏–Ω–∞–µ–º –∑–∞–≥—Ä—É–∑–∫—É –¥–∞–Ω–Ω—ã—Ö –∏–∑ {excel_file}")
    
    # –ü—Ä–æ–≤–µ—Ä—è–µ–º —Å—É—â–µ—Å—Ç–≤–æ–≤–∞–Ω–∏–µ Excel —Ñ–∞–π–ª–∞
    if not Path(excel_file).exists():
        logger.error(f"–§–∞–π–ª {excel_file} –Ω–µ –Ω–∞–π–¥–µ–Ω!")
        return False
    
    try:
        # –ß–∏—Ç–∞–µ–º Excel —Ñ–∞–π–ª
        logger.info("–ß—Ç–µ–Ω–∏–µ Excel —Ñ–∞–π–ª–∞...")
        df = pd.read_excel(excel_file, engine='openpyxl')
        logger.info(f"–ü—Ä–æ—á–∏—Ç–∞–Ω–æ {len(df)} —Å—Ç—Ä–æ–∫ –∏–∑ Excel —Ñ–∞–π–ª–∞")
        
        # –ü—Ä–æ–≤–µ—Ä—è–µ–º –Ω–∞–ª–∏—á–∏–µ –Ω–µ–æ–±—Ö–æ–¥–∏–º—ã—Ö —Å—Ç–æ–ª–±—Ü–æ–≤
        required_columns = ['document_id', 'chunk_index', 'chunk_text']
        missing_columns = [col for col in required_columns if col not in df.columns]
        
        if missing_columns:
            logger.error(f"–û—Ç—Å—É—Ç—Å—Ç–≤—É—é—Ç –Ω–µ–æ–±—Ö–æ–¥–∏–º—ã–µ —Å—Ç–æ–ª–±—Ü—ã: {missing_columns}")
            return False
        
        # –£–¥–∞–ª—è–µ–º —Å—Ç—Ä–æ–∫–∏ —Å –ø—É—Å—Ç—ã–º chunk_text
        initial_count = len(df)
        df = df.dropna(subset=['chunk_text'])
        df = df[df['chunk_text'].str.strip() != '']
        logger.info(f"–ü–æ—Å–ª–µ –æ—á–∏—Å—Ç–∫–∏ –ø—É—Å—Ç—ã—Ö —Ç–µ–∫—Å—Ç–æ–≤: {len(df)} —Å—Ç—Ä–æ–∫ (—É–¥–∞–ª–µ–Ω–æ {initial_count - len(df)})")
        
        # –°–æ–∑–¥–∞–µ–º —É–Ω–∏–∫–∞–ª—å–Ω—ã–π chunk_id –¥–ª—è –∫–∞–∂–¥–æ–π –∑–∞–ø–∏—Å–∏
        df['chunk_id'] = df['document_id'].astype(str) + '_' + df['chunk_index'].astype(str)
        
        # –ü–æ–¥–∫–ª—é—á–∞–µ–º—Å—è –∫ –±–∞–∑–µ –¥–∞–Ω–Ω—ã—Ö
        logger.info(f"–ü–æ–¥–∫–ª—é—á–µ–Ω–∏–µ –∫ –±–∞–∑–µ –¥–∞–Ω–Ω—ã—Ö: {db_path}")
        conn = sqlite3.connect(db_path)
        
        # –°–æ–∑–¥–∞–µ–º —Ç–∞–±–ª–∏—Ü—É
        create_chunks_table(conn)
        
        # –û—á–∏—â–∞–µ–º —Å—É—â–µ—Å—Ç–≤—É—é—â–∏–µ –¥–∞–Ω–Ω—ã–µ
        cursor = conn.cursor()
        cursor.execute("DELETE FROM chunks")
        conn.commit()
        logger.info("–û—á–∏—Å—Ç–∏–ª–∏ —Å—É—â–µ—Å—Ç–≤—É—é—â–∏–µ –¥–∞–Ω–Ω—ã–µ –≤ —Ç–∞–±–ª–∏—Ü–µ chunks")
        
        # –ó–∞–≥—Ä—É–∂–∞–µ–º –¥–∞–Ω–Ω—ã–µ
        logger.info("–ó–∞–≥—Ä—É–∑–∫–∞ –¥–∞–Ω–Ω—ã—Ö –≤ –±–∞–∑—É...")
        
        # –ü–æ–¥–≥–æ—Ç–∞–≤–ª–∏–≤–∞–µ–º –¥–∞–Ω–Ω—ã–µ –¥–ª—è –≤—Å—Ç–∞–≤–∫–∏
        data_to_insert = []
        for _, row in df.iterrows():
            data_to_insert.append((
                row['chunk_id'],
                int(row['document_id']),
                row.get('doc_type_short', ''),
                row.get('doc_type_full', ''),
                row.get('doc_number', ''),
                row.get('file_name', ''),
                int(row['chunk_index']),
                str(row['chunk_text']).strip()
            ))
        
        # –í—Å—Ç–∞–≤–ª—è–µ–º –¥–∞–Ω–Ω—ã–µ –ø–∞–∫–µ—Ç–∞–º–∏
        cursor.executemany('''
            INSERT OR REPLACE INTO chunks 
            (chunk_id, document_id, doc_type_short, doc_type_full, doc_number, file_name, chunk_index, chunk_text)
            VALUES (?, ?, ?, ?, ?, ?, ?, ?)
        ''', data_to_insert)
        
        conn.commit()
        
        # –ü—Ä–æ–≤–µ—Ä—è–µ–º —Ä–µ–∑—É–ª—å—Ç–∞—Ç
        cursor.execute("SELECT COUNT(*) FROM chunks")
        inserted_count = cursor.fetchone()[0]
        
        logger.info(f"–£—Å–ø–µ—à–Ω–æ –∑–∞–≥—Ä—É–∂–µ–Ω–æ {inserted_count} –∑–∞–ø–∏—Å–µ–π –≤ —Ç–∞–±–ª–∏—Ü—É chunks")
        
        # –ü–æ–∫–∞–∑—ã–≤–∞–µ–º —Å—Ç–∞—Ç–∏—Å—Ç–∏–∫—É
        cursor.execute("SELECT COUNT(DISTINCT document_id) FROM chunks")
        unique_docs = cursor.fetchone()[0]
        
        cursor.execute("SELECT COUNT(DISTINCT doc_type_short) FROM chunks WHERE doc_type_short != ''")
        unique_types = cursor.fetchone()[0]
        
        logger.info(f"–°—Ç–∞—Ç–∏—Å—Ç–∏–∫–∞:")
        logger.info(f"  - –£–Ω–∏–∫–∞–ª—å–Ω—ã—Ö –¥–æ–∫—É–º–µ–Ω—Ç–æ–≤: {unique_docs}")
        logger.info(f"  - –¢–∏–ø–æ–≤ –¥–æ–∫—É–º–µ–Ω—Ç–æ–≤: {unique_types}")
        logger.info(f"  - –í—Å–µ–≥–æ —á–∞–Ω–∫–æ–≤: {inserted_count}")
        
        conn.close()
        return True
        
    except Exception as e:
        logger.error(f"–û—à–∏–±–∫–∞ –ø—Ä–∏ –∑–∞–≥—Ä—É–∑–∫–µ –¥–∞–Ω–Ω—ã—Ö: {str(e)}", exc_info=True)
        return False

def main():
    """
    –û—Å–Ω–æ–≤–Ω–∞—è —Ñ—É–Ω–∫—Ü–∏—è
    """
    excel_file = "database_v1.xlsx"
    
    print("üóÉÔ∏è  –ó–ê–ì–†–£–ó–ö–ê –î–ê–ù–ù–´–• –í –í–ï–ö–¢–û–†–ù–£–Æ –ë–ê–ó–£")
    print("=" * 60)
    print(f"üìÑ Excel —Ñ–∞–π–ª: {excel_file}")
    print(f"üóÑÔ∏è  –ë–∞–∑–∞ –¥–∞–Ω–Ω—ã—Ö: {DB_PATH}")
    print("=" * 60)
    
    # –ü—Ä–æ–≤–µ—Ä—è–µ–º —Å—É—â–µ—Å—Ç–≤–æ–≤–∞–Ω–∏–µ —Ñ–∞–π–ª–∞
    if not Path(excel_file).exists():
        print(f"‚ùå –§–∞–π–ª {excel_file} –Ω–µ –Ω–∞–π–¥–µ–Ω!")
        print("üí° –£–±–µ–¥–∏—Ç–µ—Å—å, —á—Ç–æ —Ñ–∞–π–ª –Ω–∞—Ö–æ–¥–∏—Ç—Å—è –≤ —Ç–µ–∫—É—â–µ–π –¥–∏—Ä–µ–∫—Ç–æ—Ä–∏–∏")
        return
    
    # –ó–∞–≥—Ä—É–∂–∞–µ–º –¥–∞–Ω–Ω—ã–µ
    success = load_excel_to_database(excel_file, DB_PATH)
    
    if success:
        print("\n‚úÖ –î–ê–ù–ù–´–ï –£–°–ü–ï–®–ù–û –ó–ê–ì–†–£–ñ–ï–ù–´!")
        print("üìã –°–ª–µ–¥—É—é—â–∏–µ —à–∞–≥–∏:")
        print("  1. –ó–∞–ø—É—Å—Ç–∏—Ç–µ: python build_faiss_index.py")
        print("  2. –í–∫–ª—é—á–∏—Ç–µ –≤–µ–∫—Ç–æ—Ä–Ω—ã–π –ø–æ–∏—Å–∫ –≤ bot.py")
        print(f"üìÅ –ë–∞–∑–∞ –¥–∞–Ω–Ω—ã—Ö: {DB_PATH}")
    else:
        print("\n‚ùå –û–®–ò–ë–ö–ê –ü–†–ò –ó–ê–ì–†–£–ó–ö–ï –î–ê–ù–ù–´–•!")
        print("üìã –ü—Ä–æ–≤–µ—Ä—å—Ç–µ –ª–æ–≥–∏ –¥–ª—è –ø–æ–ª—É—á–µ–Ω–∏—è –ø–æ–¥—Ä–æ–±–Ω–æ—Å—Ç–µ–π")

if __name__ == "__main__":
    main() 